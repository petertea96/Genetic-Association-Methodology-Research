colSums(result)
set.seed(1)
M = matrix(runif(20), nrow = 5, ncol = 4)
write.csv(M, file="M.csv")
M
library(datasets)
data(iris)
?iris
View(iris)
tapply(iris$Sepal.Length, iris$Species)
tapply(iris$Sepal.Length, iris$Species, mean)
apply(iris, 2, mean)
apply(iris[, 1:4], 1, mean)
apply(iris[, 1:4], 2, mean)
colMeans(iris)
is.vector(apply(iris[, 1:4], 2, mean))
library(datasets)
data(mtcars)
View(mtcars)
mean(mtcars$mpg, mtcars$cyl)
?split
split(mtcars, mtcars$cyl)
tapply(mtcars$mpg, mtcars$cyl, mean)
15.1-26.66
debug(ls)
ls
ls()
library(datasets)
data(iris)
E
V
library(datasets)
data(iris)
View(iris)
tapply(iris$Sepal.Length, iris$Species, mean)
rowMeans(iris[, 1:4])
apply(iris[, 1:4], 1, mean)
apply(iris, 1, mean)
colMeans(iris)
apply(iris[, 1:4], 2, mean)
apply(iris, 2, mean)
data(mtcars)
mean(mtcars$mpg, mtcars$cyl)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
split(mtcars, mtcars$cyl)
with(mtcars, tapply(mpg, cyl, mean))
lapply(mtcars, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
apply(mtcars, 2, mean)
sapply(mtcars, cyl, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
View(mtcars)
tapply(mtcars$hp, mtcars$cyl, mean)
209.21429-82.63636
library(swirl)
install.packages("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf = read.csv(path2csv, stringsAsFactors = FALSE)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion(dplyr)
packageVersion("dplyr")
?tbl_df
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
names(cran)
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran,
| r_version == "3.1.1", country == "US")
filter(cran,r_version == "3.1.1", country == "US")
?Comparison
filter(cran,r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size> 100500, r_os =="linus-gnu")
filter(cran, size> 100500, r_os =="linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
select(cran, size:ip_id)
cran2=select(cran, size:ip_id)
cran2<-select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran = tbl_df(mydf)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
?n
?n_distinct
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count>679 )
top_counts
View(top_counts)
top_counts <- arrance(pack_sum, desc(count))
top_counts <- arrange(pack_sum, desc(count))
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique>465)
View(top_unique)
top_unique_sorted = arrange(top_unique, desc(unique()))
top_unique_sorted = arrange(top_unique, desc(unique)
)
top_unique_sorted <- arrange(top_unique, desc(unique))
View()
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
source('C:/Users/Peter/AppData/Local/Temp/RtmpSe8IlZ/chain1.R')
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
install.packages("APE")
paste("Rep.",1:1000, sep=" ")
rep(paste("Rep.",1:1000, sep=" "),3)
rep(paste("Rep.",1:10, sep=" "),3)
sort(rep(paste("Rep.",1:10, sep=" "),3))
?rep
rep(1:10, times=3)
sort(rep(1:10, times=3))
rep(1:1000, times=3)  %>%
sort
library(dplyr)
rep(1:1000, times=3)  %>%
sort
load("C:/Users/Peter/Documents/Uottawa/Summer Research 2018/Code to run on cluster/.RData")
View(Pheno1)
install.packages("gridExtra")
grid.table(Pheno1)
library(gridExtra)
grid.table(Pheno1)
grid.table(Pheno2)
grid.table(Pheno1)
png(filename = "pheno1.png", width=480,height=480,bg = "white")
grid.table(Pheno1)
dev.off()
Pheno1
png(filename = "pheno1.png", height = 50*nrow(Pheno1), width = 200*ncol(Pheno1),bg = "white")
grid.table(Pheno1)
dev.off()
png(filename = "pheno1.png", height = 25*nrow(Pheno1), width = 100*ncol(Pheno1),bg = "white")
grid.table(Pheno1)
dev.off()
png(filename = "pheno1.png", height = nrow(Pheno1), width = ncol(Pheno1),bg = "white")
grid.table(Pheno1)
dev.off()
png(filename = "pheno1.png", height = 25*nrow(Pheno1), width = 50*ncol(Pheno1),bg = "white")
grid.table(Pheno1)
dev.off()
png(filename = "pheno1.png", height = 25*nrow(Pheno1), width = 75*ncol(Pheno1),bg = "white")
grid.table(Pheno1)
dev.off()
library(swirl)
swirl()
str(mpg)
qplot(displ, hwy, data = mpg)
qplot(displ, hwy, data = mpg, color=drv)
qplot(displ, hwy, data = mpg, color=drv, geom=("point", "smooth"))
qplot(displ, hwy, data = mpg, color=drv, geom=c("point", "smooth"))
qplot(y=hwy, data=mpg, color=drv)
myhigh
qplot(drv, hwy, data=mpg, geom="boxplot")
qplot(drv, hwy, data=mpg, geom="boxplot", color=manufacturer)
qplot(hwy, data=mpg, fill=drv)
qplot(displ, hwy, data=mpg, facets=.~drv)
qplot(hwy, data=mpg, facets=.~drv, binwidth=2)
qplot(hwy, data=mpg, facets=drv~., binwidth=2)
qplot(displ, hwy, data=mpg, geom=c("point, smooth"), facets= .~drv)
qplot(displ, hwy, data=mpg, geom=c("point", "smooth"), facets= .~drv)
g=ggplot(mpg aes=c(displ,hwy))
g<-ggplot(mpg, aes=c(displ,hwy))
g <- ggplot(mpg, aes(displ,hwy))
summary(g)
g + geom_point()
g + geom_point() + geom_smooth()
g + geom_point() + geom_smooth(method = "lm")
g + geom_point() + geom_smooth(method = "lm") + facet_grid(.~drv)
g + geom_point() + geom_smooth(method = "lm") + facet_grid(.~drv) + ggtitle("Swirl Rules!")
g + geom_point(color="pink")
g + geom_point(color="pink", size=4)
g + geom_point(color="pink", size=4, alpha=1/2)
g + geom_point(size=4, alpha=1/2)
g + geom_point(size=4, alpha=1/2, aes(color=drv))
g + geom_point(aes(color=drv)) + labs(title="Swirl Rules!", x="Displacement")
g + geom_point(aes(color=drv)) + labs(title="Swirl Rules!", x="Displacement", y="Hwy Mileage")
g + geom_point(aes(color=drv)) + labs(title="Swirl Rules!", x="Displacement", y="Hwy Mileage")
g + geom_point(aes(color = drv)) + labs(title="Swirl Rules!") + labs(x="Displacement",y="Hwy Mileage")
g + geom_point(aes(color=drv), size=2, alpha=1/2) + geom_smooth(size=4, linetype=3, method="lm", se=FALSE)
g + geom_point(aes(color=drv)) + theme_bw(base_family = "Times")
qplot(myx, myy, type="l")
plot(myx, myy, type="l", ylim=c(-3,3))
g <- ggplot(testdat, aes(x=myx, y=myy))
g + geom_line()
g + geom_line() + ylim(-3,3)
g + geom_line() + coord_cartesian(ylim=c(-3,3))
g = ggplot()
g <- ggplot(mpg,aes(x=displ,y=hwy,color=factor(year)))
g + geom_point()
g + geom_point() + facet_grid(drv~cyl, margins = TRUE)
g + geom_point() + facet_grid(drv~cyl, margins = TRUE) + geom_smooth(method="lm", se=FALSE, color="black")
g + geom_point() + facet_grid(drv~cyl, margins = TRUE) + geom_smooth(method="lm",size=2, se=FALSE, color="black")
g + geom_point() + facet_grid(drv~cyl, margins = TRUE) + geom_smooth(method="lm",size=2, se=FALSE, color="black") + labs(x="Displacement", y="Highway Mileage", title="Swirl Rules!")
str(diamonds)
qplot(price, data=diamonds)
range(diamonds$price)
qplot(price, data=diamonds, binwidth=18497/30)
brk
counts
qplot(price, data=diamonds, binwidth=18497/30, fill=cut())
qplot(price, data=diamonds, binwidth=18497/30, fill=cut
)
qplot(price, data=diamonds, geom="density")
qplot(price, data=diamonds, geom="density", color=cut)
qplot(carat, price, data=diamonds)
qplot(carat, price, data=diamonds, shape=cut)
qplot(carat, price, data=diamonds, color=cut)
qplot(carat, price, data=diamonds, color=cut, geom_smooth(method="lm"))
qplot(carat, price, data=diamonds, color=cut)
qplot(carat,price,data=diamonds, color=cut) + geom_smooth(method="lm")
qplot(carat,price,data=diamonds, color=cut) + geom_smooth(method="lm")
qplot(carat,price,data=diamonds, color=cut, facets=.~cut) + geom_smooth(method="lm")
g=ggplot(diamonds, aes(depth, price))
g<-ggplot(diamonds, aes(depth, price))
summary(g)
g + geom_point()
g + geom_point(alpha=1/3)
cutpoints <- quantile(diamonds$carat, seq(0,1,length=4), na.rm=TRUE)
cutpoints
diamonds$car2 <- cut(diamonds$carat, cutpoints)
diamonds$car2
g <- ggplot(diamonds,aes(depth,price))
g + geom_point(alpha=1/3) + facet_grid(cut~car2)
diamonds[myd,]
g + geom_point(alpha=1/3) + facet_grid(cut~car2) + geom_smooth(method="lm", size=3, color="pink")
g + geom_point(alpha=1/3) + facet_grid(cut~car2) + geom_smooth(method="lm", size=3, color="pink")
ggplot(diamonds,aes(carat,price))+geom_boxplot()+facet_grid(.~cut)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?print.trellis
?trellis.par.set
?write.table
r = rnorm(10)
write.table(r, file="GG.txt")
install.packages("mdmr")
install.packages("MDMR")
library(MDMR)
?seq
Beta = seq(from=0.25, to = 1, by = 0.05)
Beta
knitr::opts_chunk$set(echo = TRUE)
data =c(160, 175, 180, 185, 185, 185, 190, 190, 195, 195, 195, 200, 200,
200, 200, 205, 205, 210, 210, 218, 219, 220, 222, 225, 225, 232)
data>215
p_hat = sum(data>215) / length(data)
p_hat
?rchisq
qchisq(p=0.025, df=2*n, lower.tail = FALSE)
data.3 = c(1, 4, 5, 21, 22, 28, 40, 42, 51, 53,
58, 67, 95, 124, 124, 160, 202, 260, 303, 363)
n = length(data.3)
qchisq(p=0.025, df=2*n, lower.tail = FALSE)
qchisq(p=0.975, df=2*n, lower.tail = FALSE)
qchisq(p=0.975, df=2*n)
qchisq(p=0.025, df=2*n)
data.3 = c(1, 4, 5, 21, 22, 28, 40, 42, 51, 53,
58, 67, 95, 124, 124, 160, 202, 260, 303, 363)
n = length(data.3)
my.sum = sum(data.3)
lower = 2*my.sum/qchisq(p=0.975, df=2*n)
upper =  2*my.sum/qchisq(p=0.025, df=2*n)
print(c(lower,upper))
qnorm(p=0.025)
?qnorm
qnorm(p=0.025, lower.tail = FALSE)
qnorm(p=0.05, lower.tail = FALSE)
(3*qnorm(p=0.05, lower.tail = FALSE))^2
?tnorm
qt(p=0.025)
qt(p=0.025, df=7)
qt(p=0.975, df=7)
qt(p=0.9, df=7)
qt(p=0.1, df=7)
qt(p=0.9, df=7)*sqrt(9)/sqrt(8)
1-.954
1-.954/2
(1-.954)/2
1-0.023
qnorm(p=0.977)
qnorm(p=0.9)
qnorm(p=0.95)
?qnorm
qnorm(p=0.1)
qnorm(p=0.95)
qnorm(p=0.1, lower.tail = FALSE)
qnorm(p=0.95, lower.tail = FALSE)
getwd()
?qf
qf(p=0.05, 1,34)
qf(95, 1,34)
qf(.95, 1,34)
qf(.96, 1,34)
qf(.94, 1,34)
library(caret)
library(kernlab)
data(spam)
folds = createFolds(y = spam$type, k = 10,
list = TRUE, returnTrain = TRUE)
sapply(folds, length)
nrow(spam)
?createFolds
folds
fold[1]
folds[1]
length(fold[1])
length(folds[1])
length(folds[[1])
length(folds[[1]])
nrow(spam)
4601/10
4141 + 460
folds = createFolds(y = spam$type, k = 10,
list = TRUE, returnTrain = FALSE)
sapply(folds, length)
my_model = train(type~., data=training_data, method="glm")
inTrain_indices = createDataPartition(y = spam$type,
p = 0.75, list=FALSE)
training_data = spam[inTrain_indices,]
testing_data = spam[-inTrain_indices,]
my_model = train(type~., data=training_data, method="glm")
install.packages("AppliedPredictiveModeling")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training)
names(adData)
colnames(adData)
?grep1
?grepl
grep1(pattern = "IL", x = "IL")
grepl(pattern="IL", x="IL")
grepl(pattern="IL", x=c("IL", "LKIL")
)
which(pattern = "IL", test = colnames(adData))
which(grep1(pattern = "IL", test = colnames(adData)))
which(grep1(pattern = "IL", test = colnames(adData)))
grep1
grep1(pattern = "IL", test = colnames(adData))
grepl(pattern = "IL", test = colnames(adData))
colnames(adData)
mynames = colnames(adData)
grepl(pattern = "IL", test = mynames)
grepl(pattern = "IL", test = "IL")
grepl(pattern = "IL", text = mynames)
grepl(pattern = "IL", x = mynames)
which(grepl(pattern = "IL", x = colnames(adData)))
colnames(adData)[58]
colnames(adData)[59]
colnames(adData)[60]
colnames(adData)[61]
colnames(adData)[111]
colnames(adData)[69]
library(mtcars)
install.packages("mtcars")
data(mtcars)
data(mtcars)
ls
ls()
View(mtcars)
library(kernlab)
mtcars.pca <- prcomp(mtcars[,c(1:7,10,11)], center = TRUE,scale. = TRUE)
?prcomp
mtcars.pca = prcomp(mtcars[,c(1:7,10,11)], center = TRUE,scale. = TRUE)
summary(mtcars.pca)
install.packages("devtools")
library(devtools)
install_github("vqv/ggbiplot")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
which(grepl(pattern = "IL", x = colnames(adData)))
?preProcess
pca = preProcess(training_data[,58:69], method = "pca")
pca = preProcess(training[,58:69], method = "pca")
pca
summary(pca)
trainPC = predict(pca, training[,58:69])
summary(trainPC)
a = prcomp(training[,58:69], center = TRUE,scale. = TRUE)
summary(a)
trainPC
summary(trainPC)
pca$rotation
a$rotation
my_model = train(diagnosis ~ training[,58:69], data=training, method="glm")
?train
training = training[, 58:69]
my_model = train(diagnosis ~., data=training, method="glm")
library(ISLR); library(ggplot2); library(caret)
data(Wage)
inTrain = createDataPartition(y = Wage$wage,
p=0.7, list=FALSE)
training_data = Wage[inTrain, ]; testing_data = Wage[-inTrain, ]
inTrain_indices = createDataPartition(y = spam$type,
p = 0.75, list=FALSE)
data(spam)
inTrain_indices = createDataPartition(y = spam$type,
p = 0.75, list=FALSE)
training_data = spam[inTrain_indices,]; testing_data = spam[-inTrain_indices,]
hist(training_data$capitalAve)
mean(training_data$capitalAve); sd(training_data$capitalAve)
standardised_capitalAve = (training_data$capitalAve - mean(training_data$capitalAve) ) / sd(training_data$capitalAve)
mean(standardised_capitalAve); sd(standardised_capitalAve)
my_standard = preProcess(training_data, method = c("center", "scale"))
head(my_standard)
standardised_capitalAve
?predict
mean(my_model); sd(my_model)
my_model = predict(my_standard, training_data)$capitalAve
mean(my_model); sd(my_model)
?predict
my_model = predict(object = my_standard, newdata=training_data)$capitalAve
mean(my_model); sd(my_model)
?preProcess
?knn
length("0000000010000011101111111000000001001010101100110000010001100000000111100101101111001010000001001000011")
length(0000000010000011101111111000000001001010101100110000010001100000000111100101101111001010000001001000011length())
P1 = rnorm(3)
P1
phenotype1_model = lm(P1~1)
residuals_P1 = resid(phenotype1_model)
residuals_P1
Z_ij = residuals_P1%*%t(residuals_P1)
Z_ij
N = sum(upper.tri(Z_ij))
N
upper.tri(Z_ij)
z1 <-c(rep (0,N))
n=3
count = 1
for (i in 1:(n -1)) {
for (j in (i +1): n) {
z1[ count ]= Z_ij[i,j]
count = count + 1
}
}
z1
Z_ij
setwd("C:/Users/Peter/Documents/Uottawa/2018 - 2019 Honour's project/Cluster files/Final codes/Genetic-Association-Methodology-Research/Crohns Disease/Allele Kernel Analysis/Focal Point Analysis")
focal_data = read.table("New_Allele_Kernel_Data.txt" )
View(focal_data)
colnames(focal_data) = c("Statistic", "IBS", "AM", "AS", "H1", "SKAT")
focal_data = focal_data[,-4] #Accidently added AS kernel...but we don' want to study AS
library(dplyr)
GTSM = filter(focal_data, Statistic == "GTSM")
library(reshape2)
Stacked_GTSM = melt(data=GTSM, id.vars = 1)
library(ggplot2)
ggplot(Stacked_GTSM, aes(x=value, y=..scaled.., fill=variable)) + geom_density() + facet_wrap(~variable) +
geom_vline(xintercept = 0.05, show.legend = TRUE, linetype = "dashed", color = "red") +
ggtitle("GTSR - Allele/Genotype kernel association distributions") +
xlab("P-value") + ylab("Scaled Density") +
theme_classic() +
theme(strip.background = element_rect(fill="lightgreen")) +
scale_fill_discrete(name = "Kernel")
