g + geom_point() + geom_smooth(method = "lm") + facet_grid(.~drv)
g + geom_point() + geom_smooth(method = "lm") + facet_grid(.~drv) + ggtitle("Swirl Rules!")
g + geom_point(color="pink")
g + geom_point(color="pink", size=4)
g + geom_point(color="pink", size=4, alpha=1/2)
g + geom_point(size=4, alpha=1/2)
g + geom_point(size=4, alpha=1/2, aes(color=drv))
g + geom_point(aes(color=drv)) + labs(title="Swirl Rules!", x="Displacement")
g + geom_point(aes(color=drv)) + labs(title="Swirl Rules!", x="Displacement", y="Hwy Mileage")
g + geom_point(aes(color=drv)) + labs(title="Swirl Rules!", x="Displacement", y="Hwy Mileage")
g + geom_point(aes(color = drv)) + labs(title="Swirl Rules!") + labs(x="Displacement",y="Hwy Mileage")
g + geom_point(aes(color=drv), size=2, alpha=1/2) + geom_smooth(size=4, linetype=3, method="lm", se=FALSE)
g + geom_point(aes(color=drv)) + theme_bw(base_family = "Times")
qplot(myx, myy, type="l")
plot(myx, myy, type="l", ylim=c(-3,3))
g <- ggplot(testdat, aes(x=myx, y=myy))
g + geom_line()
g + geom_line() + ylim(-3,3)
g + geom_line() + coord_cartesian(ylim=c(-3,3))
g = ggplot()
g <- ggplot(mpg,aes(x=displ,y=hwy,color=factor(year)))
g + geom_point()
g + geom_point() + facet_grid(drv~cyl, margins = TRUE)
g + geom_point() + facet_grid(drv~cyl, margins = TRUE) + geom_smooth(method="lm", se=FALSE, color="black")
g + geom_point() + facet_grid(drv~cyl, margins = TRUE) + geom_smooth(method="lm",size=2, se=FALSE, color="black")
g + geom_point() + facet_grid(drv~cyl, margins = TRUE) + geom_smooth(method="lm",size=2, se=FALSE, color="black") + labs(x="Displacement", y="Highway Mileage", title="Swirl Rules!")
str(diamonds)
qplot(price, data=diamonds)
range(diamonds$price)
qplot(price, data=diamonds, binwidth=18497/30)
brk
counts
qplot(price, data=diamonds, binwidth=18497/30, fill=cut())
qplot(price, data=diamonds, binwidth=18497/30, fill=cut
)
qplot(price, data=diamonds, geom="density")
qplot(price, data=diamonds, geom="density", color=cut)
qplot(carat, price, data=diamonds)
qplot(carat, price, data=diamonds, shape=cut)
qplot(carat, price, data=diamonds, color=cut)
qplot(carat, price, data=diamonds, color=cut, geom_smooth(method="lm"))
qplot(carat, price, data=diamonds, color=cut)
qplot(carat,price,data=diamonds, color=cut) + geom_smooth(method="lm")
qplot(carat,price,data=diamonds, color=cut) + geom_smooth(method="lm")
qplot(carat,price,data=diamonds, color=cut, facets=.~cut) + geom_smooth(method="lm")
g=ggplot(diamonds, aes(depth, price))
g<-ggplot(diamonds, aes(depth, price))
summary(g)
g + geom_point()
g + geom_point(alpha=1/3)
cutpoints <- quantile(diamonds$carat, seq(0,1,length=4), na.rm=TRUE)
cutpoints
diamonds$car2 <- cut(diamonds$carat, cutpoints)
diamonds$car2
g <- ggplot(diamonds,aes(depth,price))
g + geom_point(alpha=1/3) + facet_grid(cut~car2)
diamonds[myd,]
g + geom_point(alpha=1/3) + facet_grid(cut~car2) + geom_smooth(method="lm", size=3, color="pink")
g + geom_point(alpha=1/3) + facet_grid(cut~car2) + geom_smooth(method="lm", size=3, color="pink")
ggplot(diamonds,aes(carat,price))+geom_boxplot()+facet_grid(.~cut)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?print.trellis
?trellis.par.set
?write.table
r = rnorm(10)
write.table(r, file="GG.txt")
install.packages("mdmr")
install.packages("MDMR")
library(MDMR)
?seq
Beta = seq(from=0.25, to = 1, by = 0.05)
Beta
knitr::opts_chunk$set(echo = TRUE)
data =c(160, 175, 180, 185, 185, 185, 190, 190, 195, 195, 195, 200, 200,
200, 200, 205, 205, 210, 210, 218, 219, 220, 222, 225, 225, 232)
data>215
p_hat = sum(data>215) / length(data)
p_hat
?rchisq
qchisq(p=0.025, df=2*n, lower.tail = FALSE)
data.3 = c(1, 4, 5, 21, 22, 28, 40, 42, 51, 53,
58, 67, 95, 124, 124, 160, 202, 260, 303, 363)
n = length(data.3)
qchisq(p=0.025, df=2*n, lower.tail = FALSE)
qchisq(p=0.975, df=2*n, lower.tail = FALSE)
qchisq(p=0.975, df=2*n)
qchisq(p=0.025, df=2*n)
data.3 = c(1, 4, 5, 21, 22, 28, 40, 42, 51, 53,
58, 67, 95, 124, 124, 160, 202, 260, 303, 363)
n = length(data.3)
my.sum = sum(data.3)
lower = 2*my.sum/qchisq(p=0.975, df=2*n)
upper =  2*my.sum/qchisq(p=0.025, df=2*n)
print(c(lower,upper))
qnorm(p=0.025)
?qnorm
qnorm(p=0.025, lower.tail = FALSE)
qnorm(p=0.05, lower.tail = FALSE)
(3*qnorm(p=0.05, lower.tail = FALSE))^2
?tnorm
qt(p=0.025)
qt(p=0.025, df=7)
qt(p=0.975, df=7)
qt(p=0.9, df=7)
qt(p=0.1, df=7)
qt(p=0.9, df=7)*sqrt(9)/sqrt(8)
1-.954
1-.954/2
(1-.954)/2
1-0.023
qnorm(p=0.977)
qnorm(p=0.9)
qnorm(p=0.95)
?qnorm
qnorm(p=0.1)
qnorm(p=0.95)
qnorm(p=0.1, lower.tail = FALSE)
qnorm(p=0.95, lower.tail = FALSE)
getwd()
?qf
qf(p=0.05, 1,34)
qf(95, 1,34)
qf(.95, 1,34)
qf(.96, 1,34)
qf(.94, 1,34)
library(caret)
library(kernlab)
data(spam)
folds = createFolds(y = spam$type, k = 10,
list = TRUE, returnTrain = TRUE)
sapply(folds, length)
nrow(spam)
?createFolds
folds
fold[1]
folds[1]
length(fold[1])
length(folds[1])
length(folds[[1])
length(folds[[1]])
nrow(spam)
4601/10
4141 + 460
folds = createFolds(y = spam$type, k = 10,
list = TRUE, returnTrain = FALSE)
sapply(folds, length)
my_model = train(type~., data=training_data, method="glm")
inTrain_indices = createDataPartition(y = spam$type,
p = 0.75, list=FALSE)
training_data = spam[inTrain_indices,]
testing_data = spam[-inTrain_indices,]
my_model = train(type~., data=training_data, method="glm")
install.packages("AppliedPredictiveModeling")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training)
names(adData)
colnames(adData)
?grep1
?grepl
grep1(pattern = "IL", x = "IL")
grepl(pattern="IL", x="IL")
grepl(pattern="IL", x=c("IL", "LKIL")
)
which(pattern = "IL", test = colnames(adData))
which(grep1(pattern = "IL", test = colnames(adData)))
which(grep1(pattern = "IL", test = colnames(adData)))
grep1
grep1(pattern = "IL", test = colnames(adData))
grepl(pattern = "IL", test = colnames(adData))
colnames(adData)
mynames = colnames(adData)
grepl(pattern = "IL", test = mynames)
grepl(pattern = "IL", test = "IL")
grepl(pattern = "IL", text = mynames)
grepl(pattern = "IL", x = mynames)
which(grepl(pattern = "IL", x = colnames(adData)))
colnames(adData)[58]
colnames(adData)[59]
colnames(adData)[60]
colnames(adData)[61]
colnames(adData)[111]
colnames(adData)[69]
library(mtcars)
install.packages("mtcars")
data(mtcars)
data(mtcars)
ls
ls()
View(mtcars)
library(kernlab)
mtcars.pca <- prcomp(mtcars[,c(1:7,10,11)], center = TRUE,scale. = TRUE)
?prcomp
mtcars.pca = prcomp(mtcars[,c(1:7,10,11)], center = TRUE,scale. = TRUE)
summary(mtcars.pca)
install.packages("devtools")
library(devtools)
install_github("vqv/ggbiplot")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433);data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
which(grepl(pattern = "IL", x = colnames(adData)))
?preProcess
pca = preProcess(training_data[,58:69], method = "pca")
pca = preProcess(training[,58:69], method = "pca")
pca
summary(pca)
trainPC = predict(pca, training[,58:69])
summary(trainPC)
a = prcomp(training[,58:69], center = TRUE,scale. = TRUE)
summary(a)
trainPC
summary(trainPC)
pca$rotation
a$rotation
my_model = train(diagnosis ~ training[,58:69], data=training, method="glm")
?train
training = training[, 58:69]
my_model = train(diagnosis ~., data=training, method="glm")
library(ISLR); library(ggplot2); library(caret)
data(Wage)
inTrain = createDataPartition(y = Wage$wage,
p=0.7, list=FALSE)
training_data = Wage[inTrain, ]; testing_data = Wage[-inTrain, ]
inTrain_indices = createDataPartition(y = spam$type,
p = 0.75, list=FALSE)
data(spam)
inTrain_indices = createDataPartition(y = spam$type,
p = 0.75, list=FALSE)
training_data = spam[inTrain_indices,]; testing_data = spam[-inTrain_indices,]
hist(training_data$capitalAve)
mean(training_data$capitalAve); sd(training_data$capitalAve)
standardised_capitalAve = (training_data$capitalAve - mean(training_data$capitalAve) ) / sd(training_data$capitalAve)
mean(standardised_capitalAve); sd(standardised_capitalAve)
my_standard = preProcess(training_data, method = c("center", "scale"))
head(my_standard)
standardised_capitalAve
?predict
mean(my_model); sd(my_model)
my_model = predict(my_standard, training_data)$capitalAve
mean(my_model); sd(my_model)
?predict
my_model = predict(object = my_standard, newdata=training_data)$capitalAve
mean(my_model); sd(my_model)
?preProcess
?knn
length("0000000010000011101111111000000001001010101100110000010001100000000111100101101111001010000001001000011")
length(0000000010000011101111111000000001001010101100110000010001100000000111100101101111001010000001001000011length())
P1 = rnorm(3)
P1
phenotype1_model = lm(P1~1)
residuals_P1 = resid(phenotype1_model)
residuals_P1
Z_ij = residuals_P1%*%t(residuals_P1)
Z_ij
N = sum(upper.tri(Z_ij))
N
upper.tri(Z_ij)
z1 <-c(rep (0,N))
n=3
count = 1
for (i in 1:(n -1)) {
for (j in (i +1): n) {
z1[ count ]= Z_ij[i,j]
count = count + 1
}
}
z1
Z_ij
setwd("C:/Users/Peter/Documents/Uottawa/2018 - 2019 Honour's project/Cluster files/Final codes/Crohns Disease")
library(ape)
treename1 = paste("Merge8Million_trees_", 1, ".out", sep = "")
tree1 = read.tree(treename1)
mytree1 = tree1[[1]]
mytree1
tree1[[2]]
tree1[[3]]
transmit=cbind(1:(4*129), rep(c(1,0),2*129))
status = transmit[,2]
source('~/Uottawa/2018 - 2019 Honour\'s project/Cluster files/Final codes/Crohns Disease/Tree Kernel Analysis/Crohn_Treesimilarity.R')
source('~/Uottawa/2018 - 2019 Honour\'s project/Cluster files/Final codes/Crohns Disease/Tree Kernel Analysis/Crohn_order.R')
library(MDMR)
pval_P1_MDMR_function = function(P1, kernel.list){
p.value_MDMR_p1 <- matrix(rep (0, length(kernel.list)), nrow = 1)
## phenotype 1
for (i in 1:length(kernel.list)) {
kernel = kernel.list[[i]]
MDMR <-mdmr(X=P1 , D = kernel, perm.p = TRUE)
p.value_MDMR_p1[i] <- MDMR$stat[2 ,1]
}
#chr=c("S_IBS", "S_AM", "S_AS", "S_h1", "skat.kernel","tree1", "tree2", "tree3", "tree4", "tree5")
chr=c("tree1", "tree2", "tree3", "tree4", "tree5")
colnames(p.value_MDMR_p1) <-chr
return(as.vector(p.value_MDMR_p1))
}
get.tree.kernels = function(mytree){
# Various (tree) similarity matrices
sim1=treeSimilarity(mytree) # TMRCA - time to present of pairs mrca
sim2=treeSimilarity(mytree,propn=TRUE) # (TMRCA - time to present of pairs mrca)/TMRCA
sim3=treeSimilarity(mytree, method="ranks") # Rank of coalescent event for each pairs mrca (oldest ranked 1)
sim4=treeSimilarity(mytree, method="sdscaled") # Like 1, but intercoalescence times divided by mean/sd
sim5=treeSimilarity(mytree, method="sdscaled",propn=T) # Like 2, but intercoalescence times divided by mean/sd
#Sorted issue:
tree1=order(sim1[[1]], sim1[[2]])
tree2=order(sim2[[1]], sim2[[2]])
tree3=order(sim3[[1]], sim3[[2]])
tree4=order(sim4[[1]], sim4[[2]])
tree5=order(sim5[[1]], sim5[[2]])
#Kernel Matrices
kernel.list = list(tree1, tree2, tree3, tree4, tree5)
#kernel.list = list(S_IBS, S_AM, S_AS, S_h1, skat.kernel,
#                  tree1, tree2, tree3, tree4, tree5)
names(kernel.list) = c("tree1", "tree2", "tree3",
"tree4", "tree5")
return(kernel.list)
#names(kernel.list) = c("S_IBS", "S_AM", "S_AS",
#                      "S_h1", "skat.kernel","tree1", "tree2", "tree3", "tree4", "tree5")
}
transmit=cbind(1:(4*129), rep(c(1,0),2*129))
status = transmit[,2]
j=1
mytree = trees[[j]]
mytree_kernels = get.tree.kernels(mytree)
mytree= tree1[[1]]
mytree_kernels = get.tree.kernels(mytree)
length(mytree_kernels)
library(SKAT)
library(MDMR)
trees = tree1
GTSR_results=matrix(ncol=5,nrow=length(trees))
MDMR_results=matrix(ncol=5,nrow=length(trees))
SKAT_results=matrix(ncol=5,nrow=length(trees))
null.model = SKAT_Null_Model(status ~ 1, out_type="D")
SKAT.stat=vector("list", length(mytree_kernels))
for (i in 1:length(mytree_kernels)){
#Fill in list of SKAT p-values
SKAT.stat[[i]]= tryCatch(SKAT(Z=as.matrix(G), obj=null.model, kernel = mytree_kernels[[i]])$Q,
error = function(e)
paste("NA"))
#-----||-----||-----|| - What is tryCatch()?  - ||-----||-----||-----#
#--> tryCatch() is implemented because in some datasets, we get an error.
#--> Essentially, some product kernels seem to not produce any positive eigenvalues
# and we can't compute p-values. This only happens a small amount of times.
#--> With the tryCatch(), if this error occurs we assign an NA value and just move on without
#disrupting the code.
#-----||-----||-----|| - What is tryCatch()?  - ||-----||-----||-----#
}
for (i in (1:(length(SKAT.stat)))){
#Add SKAT p-values to our results table.
SKAT_results[j,i] = SKAT.stat[[i]]
}
SKAT_results
head(SKAT_results)
mytree_kernels[[1]]
G=read.table("Processed_haplodata.txt")
setwd("C:/Users/Peter/Documents/Uottawa/2018 - 2019 Honour's project/Cluster files/Final codes/Crohns Disease")
SKAT_results=matrix(ncol=5,nrow=length(trees))
j
SKAT.stat=vector("list", length(mytree_kernels))
length(mytree_kernels)
G=read.table("Processed_haplodata.txt")
for (i in 1:length(mytree_kernels)){
#Fill in list of SKAT p-values
SKAT.stat[[i]]= tryCatch(SKAT(Z=as.matrix(G), obj=null.model, kernel = mytree_kernels[[i]])$Q,
error = function(e)
paste("NA"))
#-----||-----||-----|| - What is tryCatch()?  - ||-----||-----||-----#
#--> tryCatch() is implemented because in some datasets, we get an error.
#--> Essentially, some product kernels seem to not produce any positive eigenvalues
# and we can't compute p-values. This only happens a small amount of times.
#--> With the tryCatch(), if this error occurs we assign an NA value and just move on without
#disrupting the code.
#-----||-----||-----|| - What is tryCatch()?  - ||-----||-----||-----#
}
SKAT.stat
for (i in (1:(length(SKAT.stat)))){
#Add SKAT p-values to our results table.
SKAT_results[j,i] = SKAT.stat[[i]]
}
SKAT_results
head(SKAT_results)
stat.gtsm = similarity.regression.tree(P1=status,n=length(status), kernel.list=mytree_kernels)
similarity.regression.tree = function(P1,n, kernel.list ){
phenotype1_model = lm(P1~1)
## compute vector of (P1i -mu.p1_0)
residuals_P1 = resid(phenotype1_model)
## compute n by n trait similarity matrix of phenotype 1
Z_ij = residuals_P1%*%t(residuals_P1)
#####||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----#####
#July 25th, 2018
#N is the number of upper diagonal elements?
N = sum(upper.tri(Z_ij))
##I extract the values of the upper diagonal of matrices Z1
z1 <-c(rep (0,N))
count = 1
for (i in 1:(n -1)) {
for (j in (i +1): n) {
z1[ count ]= Z_ij[i,j]
count = count + 1
}
}
#chr is a vector of list names of the kernels???
##chr=c("S_IBS", "S_AM", "S_AS", "S_LIN", "S_REC", "S_QUAD", "S_012", "S_123",
##     "S_124", "S_h1", "skat.kernel","tree1", "tree2", "tree3", "tree4", "tree5")
chr=c("tree1", "tree2", "tree3", "tree4", "tree5")
#s_vectors: The columns of s_vector contain similarities of distinct pairs of individuals by
#each kernel. I assume that it is of dimension (16x4950)
s_vectors = c()
for (i in 1:length(kernel.list)){
kernel = kernel.list[[i]]
#Extract the upper diagonal:
upper_diagonal <-c(rep (0,N))
count = 1
for (ii in 1:(n -1)) {
for (j in (ii +1): n) {
upper_diagonal[count]= kernel[ii,j]
count = count + 1
}
}
s_vectors=cbind(s_vectors,upper_diagonal)
}
colnames(s_vectors) = chr
#####||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----#####
## check the equality of last two values
# z1[N -1] == Z1[n -2,n]
#z1[N] == Z1[n -1,n]
## 1. Phenotype 1
## compute wald test statistic of phenotype 1 stored in vector: wald.pheno1
wald.pheno1 = matrix (rep(0, length(chr)), ncol = length(chr))
for (i in 1: length(chr)) {
gene_trait_lm  = lm(z1~ s_vectors[,i])
wald.pheno1[i] =(summary(gene_trait_lm)$coefficients[2 ,3])^2
}
## compute permuted wald test statistic of phenotype 1
## stored in matrix wald.pheno1.permu
## recall the columns of s_ vectors contains similarities of distinct pairs
## of individuals computed based on a particular kernel
colnames(wald.pheno1) = chr
## compute permuted p- values of phenotype 1 denoted by permu .p1.p
return(as.vector(wald.pheno1))
}
stat.gtsm = similarity.regression.tree(P1=status,n=length(status), kernel.list=mytree_kernels)
stat.gtsm
for (i in (1:length(stat.gtsm))){
#Fill in results table with GTSR p-values
GTSR_results[j,i] = stat.gtsm[i]
}
GTSR_results
head(GTSR_results)
stat.MDMR = pval_P1_MDMR_function(P1=status, kernel.list=mytree_kernels)
?mdmr
pval_P1_MDMR_function = function(P1, kernel.list){
p.value_MDMR_p1 <- matrix(rep (0, length(kernel.list)), nrow = 1)
## phenotype 1
for (i in 1:length(kernel.list)) {
kernel = kernel.list[[i]]
MDMR <-mdmr(X=P1 , D = kernel, nperm=0)
p.value_MDMR_p1[i] <- MDMR$stat[2 ,1]
}
#chr=c("S_IBS", "S_AM", "S_AS", "S_h1", "skat.kernel","tree1", "tree2", "tree3", "tree4", "tree5")
chr=c("tree1", "tree2", "tree3", "tree4", "tree5")
colnames(p.value_MDMR_p1) <-chr
return(as.vector(p.value_MDMR_p1))
}
stat.MDMR = pval_P1_MDMR_function(P1=status, kernel.list=mytree_kernels)
stat.MDMR
pval_P1_MDMR_function = function(P1, kernel.list){
p.value_MDMR_p1 <- matrix(rep (0, length(kernel.list)), nrow = 1)
## phenotype 1
for (i in 1:length(kernel.list)) {
kernel = kernel.list[[i]]
MDMR <-mdmr(X=P1 , D = kernel)
p.value_MDMR_p1[i] <- MDMR$stat[2 ,1]
}
#chr=c("S_IBS", "S_AM", "S_AS", "S_h1", "skat.kernel","tree1", "tree2", "tree3", "tree4", "tree5")
chr=c("tree1", "tree2", "tree3", "tree4", "tree5")
colnames(p.value_MDMR_p1) <-chr
return(as.vector(p.value_MDMR_p1))
}
stat.MDMR = pval_P1_MDMR_function(P1=status, kernel.list=mytree_kernels)
stat.MDMR
pval_P1_MDMR_function = function(P1, kernel.list){
p.value_MDMR_p1 <- matrix(rep (0, length(kernel.list)), nrow = 1)
## phenotype 1
for (i in 1:length(kernel.list)) {
kernel = kernel.list[[i]]
MDMR <-mdmr(X=P1 , D = kernel, perm.p = TRUE)
p.value_MDMR_p1[i] <- MDMR$stat[2 ,1]
}
#chr=c("S_IBS", "S_AM", "S_AS", "S_h1", "skat.kernel","tree1", "tree2", "tree3", "tree4", "tree5")
chr=c("tree1", "tree2", "tree3", "tree4", "tree5")
colnames(p.value_MDMR_p1) <-chr
return(as.vector(p.value_MDMR_p1))
}
stat.MDMR = pval_P1_MDMR_function(P1=status, kernel.list=mytree_kernels)
stat.MDMR
colnames(SKAT_results) = c("Tree1","Tree2", "Tree3", "Tree4", "Tree5")
head(SKAT_results)
colnames(MDMR_results) = c("Tree1","Tree2", "Tree3", "Tree4", "Tree5")
colnames(GTSR_results) = c("Tree1","Tree2", "Tree3", "Tree4", "Tree5")
head(GTSR_results)
